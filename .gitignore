library("randomForest")
train <- read.table("train.csv", sep=",", header=TRUE)
test <- read.table("test.csv", sep=",", header=TRUE)
cat.var.names <- c(paste("Product_Info_", c(1:3,5:7), sep=""), paste("Employment_Info_", c(2,3,5), sep=""), paste("InsuredInfo_", 1:7, sep=""), paste("Insurance_History_", c(1:4,7:9), sep=""), "Family_Hist_1", paste("Medical_History_", c(2:14, 16:23, 25:31, 33:41), sep=""))
cont.var.names <- c("Product_Info_4", "Ins_Age", "Ht", "Wt", "BMI", "Employment_Info_1", "Employment_Info_4", "Employment_Info_6", "Insurance_History_5", "Family_Hist_2", "Family_Hist_3", "Family_Hist_4", "Family_Hist_5")
disc.var.names <- c("Medical_History_1", "Medical_History_15", "Medical_History_24", "Medical_History_32", paste("Medical_Keyword_", 1:48, sep=""))


train.cat <- train[, cat.var.names]
test.cat <- test[, cat.var.names]

train.cont <- train[, cont.var.names]
test.cont <- test[, cont.var.names]

train.disc <- train[, disc.var.names]
test.disc <- test[, disc.var.names]

setwd("C:/Users/Carbon/Desktop/DATA/HP ultimo/pentdrives HP/2/R programs/randomForest")
source("MLUtils.R"); #load all the utils I have developed

##################### borro los valores NA de train.cont ######################
library("e1071")
source("deleteNA.R")

train.cont$Response<-train$Response
#Elimino los NA
train.cont.NAout<-deleteNA(train.cont)
#Transformo las etiquetas de Response en 0,1 para que las etiquetas sean binarias
train.cont.NAout[(which(train.cont.NAout$Response<=4)),"Response"]<-0
train.cont.NAout[(which(train.cont.NAout$Response>4)),"Response"]<-1

################ train, valid y test set ####################
train_set<-train.cont.NAout
valid_set<-train.cont.NAout
test_set<-train.cont.NAout

###################tomo pequeña muestra del total del conjunto###########
index1<-1:7000
index2<-7000:9000

train_set<-train.cont.NAout[index1, ]
valid_set<-train.cont.NAout[index2, ]

#############################################################################
###################### hace por defecto REGRESIÓN:###########################
#############################################################################



################################### NO FUNCIONA ############################################
train_set_r<-process_dataset(train_set,0.5,scale="Y",normalization="Y",rem_feats_useless="Y") #0.5????
valid_set_r<-process_dataset(test_set,0.5,scale="Y",normalization="Y",rem_feats_useless="Y") #0.5????
#Warning in pre_process_options(method, column_types) :
#The following pre-processing methods were eliminated: 'center', 'scale'
############################################################################################
train.rf<-randomForest(train_set[,-14],train_set[,14], cutoff = 0.5) #prox,cutoff?
train.rf
# Call:
#   randomForest(x = train_set[, -14], y = train_set[, 14], cutoff = 0.5) 
# Type of random forest: regression
# Number of trees: 500
# No. of variables tried at each split: 4
# 
# Mean of squared residuals: 0.1756205
# % Var explained: 8.79


#Predicción#
rf.pred  = round (predict( train.rf , valid_set[,-14]))


##Acc##
z<-table(rf.pred, valid_set[,14])
z

# rf.pred    0    1
#       0   94   49
#       1  449 1409

sum(rf.pred==valid_set[,14])/length(valid_set[,14])
#[1] 0.7511244

############# PAQUETES REQUERIDOS PARA USAR TRAINCLASSIFIERS ####################
require(caret)
require(corrplot)
require(ROCR) 

source("MLUtils.R"); #load all the utils I have developed

# F1measureCaret definida en MLUtils: si peds<>trues nos da medidas de precision ROC
postResample (valid_set[,14],rf.pred)
#       RMSE   Rsquared 
# 0.03162278 0.99484154

#medidas pendientes
F1measureCaret(valid_set[,14],rf.pred)
twoClassSummary(valid_set[,14],rf.pred)
defaultSummary(valid_set[,14],rf.pred)

##################EVALUATION##################################
prf(rf.pred, valid_set[,14])
#            Acc       P_0       R_0      F1_0       P_1       R_1      F1_1    F1_avg
# [1,] 0.7511244 0.1731123 0.6573427 0.2740525 0.9663923 0.7583423 0.8498191 0.5619358

confusionMatrix ( rf.pred , valid_set[,14] )        
# Confusion Matrix and Statistics
# 
# Reference
# Prediction    0    1
#           0   94   49
#           1  449 1409
# 
# Accuracy : 0.7511          
# 95% CI : (0.7316, 0.7699)
# No Information Rate : 0.7286          
# P-Value [Acc > NIR] : 0.01212         
# 
# Kappa : 0.1814          
# Mcnemar's Test P-Value : < 2e-16         
#                                           
#             Sensitivity : 0.17311         
#             Specificity : 0.96639         
#          Pos Pred Value : 0.65734         
#          Neg Pred Value : 0.75834         
#              Prevalence : 0.27136         
#          Detection Rate : 0.04698         
#    Detection Prevalence : 0.07146         
#       Balanced Accuracy : 0.56975         
#                                           
#        'Positive' Class : 0                         

#############################################################################
##################### para la CLASIFICACIÓN:#################################
#############################################################################


#(names(train_set)=="Response")# vector lógico
#colnames(train_set)[ colnames(train_set) == "Response" ] <- "nombre que quiera" ##cambiar nom col

train_set[,"Response"]<-as.factor(train_set[,"Response"])

train.rf<-randomForest(train_set[,-14],train_set[,14]) #prox, ¿cutoff = 0.5 incorrect ?
train.rf<-randomForest(train_set[,-14],train_set[,14],importance=TRUE)
train.rf

# Call:
#   randomForest(x = train_set[, -14], y = train_set[, 14], importance = TRUE) 
# Type of random forest: classification
# Number of trees: 500
# No. of variables tried at each split: 3
# 
# OOB estimate of  error rate: 24.57%
# Confusion matrix:
#   0    1 class.error
# 0 316 1506   0.8265642
# 1 214 4964   0.0413287

varImpPlot(train.rf)

#Predicción#
rf.pred  <- (predict( train.rf , valid_set[,-14]))
confusionMatrix ( rf.pred , valid_set[,14] ) 

# Confusion Matrix and Statistics
# 
# Reference
# Prediction    0    1
#           0   89   49
#           1  454 1409
# 
# Accuracy : 0.7486         
# 95% CI : (0.729, 0.7675)
# No Information Rate : 0.7286         
# P-Value [Acc > NIR] : 0.02288        
# 
# Kappa : 0.1701         
# Mcnemar's Test P-Value : < 2e-16        
# 
# Sensitivity : 0.16390        
# Specificity : 0.96639        
# Pos Pred Value : 0.64493        
# Neg Pred Value : 0.75631        
# Prevalence : 0.27136        
# Detection Rate : 0.04448        
# Detection Prevalence : 0.06897        
# Balanced Accuracy : 0.56515        
# 
# 'Positive' Class : 0    

##Acc##
z<-table(valid_set[,14],rf.pred)
z
rf.pred
#      0    1
# 0   89  454
# 1   49 1409
sum(rf.pred==valid_set[,14])/length(valid_set[,14])
#[1] 0.7486257


#predicción con prob sólo disponible para el modelo de clasificación:
rf.pred.prob  <- predict( train.rf , valid_set[,-14] , type = "prob" )

head(rf.pred.prob) # tiene los 2000 elementos del conjunto de predicciones
#          0     1
# 7000 0.676 0.324
# 7001 0.166 0.834
# 7002 0.180 0.820
# 7003 0.306 0.694
# 7004 0.618 0.382
# 7005 0.152 0.848

rf.pred.class <- predict( train.rf , valid_set[,-14] )
